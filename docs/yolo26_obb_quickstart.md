# YOLO26-OBB å¿«é€Ÿå…¥é—¨æŒ‡å—

## ç®€ä»‹

æœ¬æ–‡æ¡£æä¾› YOLO26-OBB æ—‹è½¬ç›®æ ‡æ£€æµ‹æ¨¡å‹åœ¨ lite.ai.toolkit ä¸­çš„å¿«é€Ÿå…¥é—¨æŒ‡å—ã€‚

## åŠŸèƒ½æ¦‚è¿°

YOLO26-OBB æ˜¯ä¸€ä¸ªç”¨äºæ—‹è½¬ç›®æ ‡æ£€æµ‹ï¼ˆOriented Bounding Box Detectionï¼‰çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼š

- âœ… æ£€æµ‹ä»»æ„æ–¹å‘çš„ç›®æ ‡
- âœ… è¾“å‡ºæ—‹è½¬è§’åº¦ä¿¡æ¯
- âœ… æ”¯æŒ ONNXRuntime å’Œ TensorRT åç«¯
- âœ… è‡ªå®šä¹‰ç±»åˆ«åç§°
- âœ… ç«¯åˆ°ç«¯ NMS åå¤„ç†

## å¿«é€Ÿå¼€å§‹ï¼ˆ5åˆ†é’Ÿï¼‰

### æ­¥éª¤ 1: å‡†å¤‡æ¨¡å‹

```bash
cd /path/to/lite.ai.toolkit/test/model

# å¦‚æœå·²æœ‰ PT æ¨¡å‹ï¼Œå¯¼å‡º ONNX
conda activate yolo
python3 << EOF
from ultralytics import YOLO
model = YOLO('yolo26m-obb/weights/best.pt')
model.export(format='onnx', opset=11, simplify=True, dynamic=False, imgsz=640)
EOF
```

### æ­¥éª¤ 2: ç¼–å†™ä»£ç 

åˆ›å»º `demo.cpp`ï¼š

```cpp
#include "lite/lite.h"

int main()
{
    // 1. åˆ›å»ºæ£€æµ‹å™¨
    auto *detector = new lite::onnxruntime::cv::detection::YOLO26OBB(
        "yolo26m-obb/weights/best.onnx");
    
    // 2. è®¾ç½®ç±»åˆ«åç§°ï¼ˆå¯é€‰ï¼‰
    detector->set_class_names({"ExpressBillSeg", "BarCode", "2DCode"});
    
    // 3. åŠ è½½å›¾åƒ
    cv::Mat img = cv::imread("test.jpg");
    
    // 4. æ‰§è¡Œæ£€æµ‹
    std::vector<lite::types::BoxfWithAngle> boxes;
    detector->detect(img, boxes, 0.25f);  // ç½®ä¿¡åº¦é˜ˆå€¼ 0.25
    
    // 5. ç»˜åˆ¶ç»“æœ
    lite::utils::draw_boxes_with_angle_inplace(img, boxes);
    cv::imwrite("result.jpg", img);
    
    // 6. æ‰“å°ç»“æœ
    for (const auto &box : boxes)
    {
        std::cout << box.label_text << ": " << box.score 
                  << " @ " << (box.angle * 180.0 / CV_PI) << "Â°\n";
    }
    
    delete detector;
    return 0;
}
```

### æ­¥éª¤ 3: ç¼–è¯‘å’Œè¿è¡Œ

```bash
# ç¼–è¯‘é¡¹ç›®
cd lite.ai.toolkit
mkdir build && cd build
cmake -DENABLE_ONNXRUNTIME=ON ..
make -j$(nproc)

# ç¼–è¯‘ä½ çš„ demo
g++ demo.cpp -o demo \
    -I../lite \
    -L./lib -llite.ai.toolkit \
    `pkg-config --cflags --libs opencv4`

# è¿è¡Œ
./demo
```

## è¾“å‡ºç»“æœ

ç¨‹åºä¼šç”Ÿæˆï¼š

1. **å›¾åƒæ–‡ä»¶**: `result.jpg` - å¸¦æ—‹è½¬æ¡†çš„å¯è§†åŒ–ç»“æœ
2. **æ§åˆ¶å°è¾“å‡º**: æ£€æµ‹æ¡†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç±»åˆ«ã€ç½®ä¿¡åº¦ã€è§’åº¦ç­‰

## æ—‹è½¬æ¡†ç»“æ„

```cpp
struct BoxfWithAngle {
    float x1, y1, x2, y2;     // è½´å¯¹é½è¾¹ç•Œæ¡†ï¼ˆå¤–æ¥çŸ©å½¢ï¼‰
    float cx, cy;             // æ—‹è½¬æ¡†ä¸­å¿ƒç‚¹
    float width, height;      // æ—‹è½¬æ¡†å®½é«˜
    float angle;              // æ—‹è½¬è§’åº¦ï¼ˆå¼§åº¦ï¼‰
    float score;              // ç½®ä¿¡åº¦ [0, 1]
    unsigned int label;       // ç±»åˆ« ID
    const char *label_text;   // ç±»åˆ«åç§°
};
```

## TensorRT åŠ é€Ÿï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰

### å¯¼å‡º TensorRT Engine

```python
from ultralytics import YOLO

model = YOLO('yolo26m-obb/weights/best.pt')
model.export(format='engine', device=0, half=True)  # FP16 ç²¾åº¦
```

### ä½¿ç”¨ TensorRT

```cpp
#include "lite/lite.h"

int main()
{
    // ä½¿ç”¨ TensorRT åç«¯ï¼ˆGPU åŠ é€Ÿï¼‰
    auto *detector = new lite::trt::cv::detection::YOLO26OBB(
        "yolo26m-obb/weights/best.engine");
    
    // è®¾ç½®è¾“å…¥æ ¼å¼ï¼ˆOpenCV é»˜è®¤ BGRï¼‰
    detector->setInputFormat(
        lite::trt::cv::detection::YOLO26OBB::ImageFormat::BGR);
    
    // æ£€æµ‹ï¼ˆå…¶ä½™ä»£ç ä¸ ONNXRuntime ç›¸åŒï¼‰
    std::vector<lite::types::BoxfWithAngle> boxes;
    cv::Mat img = cv::imread("test.jpg");
    detector->detect(img, boxes, 0.25f);
    
    // ... å¤„ç†ç»“æœ ...
    
    delete detector;
    return 0;
}
```

## å¸¸ç”¨å‚æ•°é…ç½®

### æ£€æµ‹å‚æ•°

```cpp
detector->detect(
    img,                // è¾“å…¥å›¾åƒï¼ˆBGR æ ¼å¼ï¼‰
    boxes,              // è¾“å‡ºæ—‹è½¬æ¡†
    0.25f,              // score_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
    0.45f,              // iou_threshold: NMS IoU é˜ˆå€¼ï¼ˆæ¨¡å‹å·²å¤„ç†ï¼Œæ­¤å‚æ•°è¢«å¿½ç•¥ï¼‰
    300                 // topk: æœ€å¤§æ£€æµ‹æ•°é‡
);
```

### æ¨èé…ç½®

| åœºæ™¯ | score_threshold | topk | è¯´æ˜ |
|------|----------------|------|------|
| é«˜ç²¾åº¦ | 0.5 - 0.7 | 100 | å‡å°‘è¯¯æ£€ |
| å¹³è¡¡ | 0.25 - 0.4 | 300 | é»˜è®¤é…ç½® |
| é«˜å¬å› | 0.1 - 0.2 | 500 | æ£€æµ‹æ›´å¤šç›®æ ‡ |

## å¯è§†åŒ–ç»“æœ

### ç»˜åˆ¶æ—‹è½¬æ¡†

```cpp
// æ–¹æ³• 1: ç›´æ¥åœ¨åŸå›¾ä¸Šç»˜åˆ¶
lite::utils::draw_boxes_with_angle_inplace(img, boxes);
cv::imwrite("result.jpg", img);

// æ–¹æ³• 2: ä¿ç•™åŸå›¾ï¼Œè¿”å›æ–°å›¾åƒ
cv::Mat result = lite::utils::draw_boxes_with_angle(img, boxes);
cv::imwrite("result.jpg", result);
```

### è‡ªå®šä¹‰ç»˜åˆ¶

```cpp
#include <opencv2/opencv.hpp>

for (const auto &box : boxes)
{
    // è®¡ç®—æ—‹è½¬çŸ©å½¢çš„å››ä¸ªé¡¶ç‚¹
    cv::RotatedRect rbox(
        cv::Point2f(box.cx, box.cy),
        cv::Size2f(box.width, box.height),
        box.angle * 180.0f / CV_PI  // è½¬æ¢ä¸ºåº¦æ•°
    );
    
    cv::Point2f vertices[4];
    rbox.points(vertices);
    
    // ç»˜åˆ¶æ—‹è½¬çŸ©å½¢
    for (int i = 0; i < 4; i++)
    {
        cv::line(img, vertices[i], vertices[(i + 1) % 4], 
                 cv::Scalar(0, 255, 0), 2);
    }
    
    // ç»˜åˆ¶æ ‡ç­¾
    std::string label = std::string(box.label_text) + ": " + 
                       std::to_string(box.score).substr(0, 4);
    cv::putText(img, label, vertices[0], 
                cv::FONT_HERSHEY_SIMPLEX, 0.5, 
                cv::Scalar(0, 0, 255), 2);
}
```

## æ€§èƒ½å¯¹æ¯”

| åç«¯ | å¹³å° | æ¨ç†æ—¶é—´ (640x640) | ç›¸å¯¹æ€§èƒ½ |
|------|------|-------------------|---------|
| ONNXRuntime | CPU | ~100ms | 1x |
| ONNXRuntime | GPU | ~15ms | 6.7x âš¡ |
| TensorRT FP32 | GPU | ~10ms | 10x âš¡âš¡ |
| TensorRT FP16 | GPU | ~5ms | 20x âš¡âš¡âš¡ |

*æµ‹è¯•ç¯å¢ƒ: AMD Ryzen 9 8945HX, NVIDIA RTX 4060*

## å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜ 1: æ¨¡å‹åŠ è½½å¤±è´¥

```
Error: Cannot load model file
```

**è§£å†³æ–¹æ¡ˆ**:
- æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
- ç¡®è®¤æ–‡ä»¶å­˜åœ¨ä¸”æœ‰è¯»å–æƒé™
- ONNX æ¨¡å‹æ£€æŸ¥ï¼š`python3 -c "import onnx; onnx.checker.check_model('model.onnx')"`

### é—®é¢˜ 2: æ£€æµ‹ç»“æœä¸ºç©º

```
Detected Boxes: 0
```

**è§£å†³æ–¹æ¡ˆ**:
- é™ä½ `score_threshold`ï¼ˆå¦‚ 0.1ï¼‰
- æ£€æŸ¥è¾“å…¥å›¾åƒæ˜¯å¦æ­£ç¡®åŠ è½½
- ç¡®è®¤æ¨¡å‹ä¸æ•°æ®é›†åŒ¹é…

### é—®é¢˜ 3: TensorRT Engine åŠ è½½å¤±è´¥

```
Error: TensorRT engine not properly initialized
```

**è§£å†³æ–¹æ¡ˆ**:
- åœ¨ç›®æ ‡ GPU ä¸Šé‡æ–°ç”Ÿæˆ Engine æ–‡ä»¶
- æ£€æŸ¥ CUDAã€cuDNNã€TensorRT ç‰ˆæœ¬å…¼å®¹æ€§
- ç¡®è®¤ GPU æœ‰è¶³å¤Ÿæ˜¾å­˜

### é—®é¢˜ 4: è§’åº¦æ˜¾ç¤ºå¼‚å¸¸

**è§£å†³æ–¹æ¡ˆ**:
```cpp
// è§’åº¦æ˜¯å¼§åº¦å€¼ï¼Œéœ€è¦è½¬æ¢ä¸ºåº¦æ•°
float degree = box.angle * 180.0 / CV_PI;

// å½’ä¸€åŒ–åˆ° [0, 360) èŒƒå›´
if (degree < 0) degree += 360.0;
```

## è¿›é˜¶ç”¨æ³•

### æ‰¹é‡å¤„ç†å›¾åƒ

```cpp
std::vector<std::string> image_paths = {
    "img1.jpg", "img2.jpg", "img3.jpg"
};

for (const auto &path : image_paths)
{
    cv::Mat img = cv::imread(path);
    std::vector<lite::types::BoxfWithAngle> boxes;
    
    detector->detect(img, boxes, 0.25f);
    
    // ä¿å­˜ç»“æœ
    std::string save_path = "result_" + 
        path.substr(path.find_last_of("/\\") + 1);
    lite::utils::draw_boxes_with_angle_inplace(img, boxes);
    cv::imwrite(save_path, img);
}
```

### è¿‡æ»¤ç‰¹å®šç±»åˆ«

```cpp
std::vector<lite::types::BoxfWithAngle> boxes;
detector->detect(img, boxes, 0.25f);

// åªä¿ç•™"BarCode"ç±»åˆ«
std::vector<lite::types::BoxfWithAngle> barcodes;
for (const auto &box : boxes)
{
    if (std::string(box.label_text) == "BarCode")
    {
        barcodes.push_back(box);
    }
}

std::cout << "Found " << barcodes.size() << " barcodes\n";
```

### è®¡ç®—æ—‹è½¬çŸ©å½¢çš„é¢ç§¯

```cpp
for (const auto &box : boxes)
{
    float area = box.width * box.height;
    std::cout << "Box area: " << area << " pixelsÂ²\n";
}
```

## ä¸‹ä¸€æ­¥

- ğŸ“– é˜…è¯»å®Œæ•´æ–‡æ¡£ï¼š[yolo26_obb_support.md](yolo26_obb_support.md)
- ğŸ”§ æŸ¥çœ‹ç¤ºä¾‹ä»£ç ï¼š`examples/lite/cv/test_lite_yolo26_obb.cpp`
- ğŸš€ äº†è§£ TensorRT ä¼˜åŒ–ï¼š[TensorRT é›†æˆæŒ‡å—](tensorrt/tensorrt-linux-x86_64.zh.md)
- ğŸ’¡ å‚ä¸è´¡çŒ®ï¼š[è´¡çŒ®æŒ‡å—](contrib/CONTRIBUTING.zh.md)

## æ”¯æŒä¸åé¦ˆ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- GitHub Issues: [lite.ai.toolkit/issues](https://github.com/DefTruth/lite.ai.toolkit/issues)
- é‚®ä»¶: support@lite.ai.toolkit.orgï¼ˆç¤ºä¾‹ï¼‰

---

**æœ€åæ›´æ–°**: 2026-02-11  
**ç‰ˆæœ¬**: v1.0.0
